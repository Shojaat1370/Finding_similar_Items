{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQshmAs0gcy_"
   },
   "source": [
    "# **Finding similar items**\n",
    "\n",
    "### Project for the **Algorithms for massive data course**\n",
    "\n",
    "\n",
    "MSc, Data Science for Economics*\n",
    "\n",
    "Shojaat Joodi Bigdilo\n",
    "\n",
    "June 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBv3mYjYhJDJ",
    "outputId": "fd5eabf1-cc13-45df-f0bd-7d94e675c6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# connecting my Google Drive and google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_p7QCZgXgb8g"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkCUkBEMgb5e",
    "outputId": "12d8a724-d018-4683-fc23-4a6d53c6a24e"
   },
   "outputs": [],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMbUdvWqgb3M",
    "outputId": "bc9e3638-5a9c-4b51-e6d3-5256eecdd820"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HCl_E-Fbgb0Z"
   },
   "outputs": [],
   "source": [
    "# connecting to Kaggle\n",
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = 'xxxxxxxxx'\n",
    "\n",
    "os.environ['KAGGLE_KEY'] = 'xxxxxxxxx' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "E_fD3_YohvxM"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d asaniczka/1-3m-linkedin-jobs-and-skills-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EkpvFtXHhvui"
   },
   "outputs": [],
   "source": [
    "extract_to_path  = \"/content/gdrive/My Drive/Massive_Data_Project/Job_Dataset\"\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile('1-3m-linkedin-jobs-and-skills-2024.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7Uk6S2C1hvZs"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct, udf\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, MinHashLSH, Normalizer\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField, IntegerType\n",
    "\n",
    "from pyspark.sql.functions import lower, regexp_replace, size\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import string\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "H3kWgxGxjJfH",
    "outputId": "f1b3be1f-f19f-4853-8fe7-4f6acf3f0170"
   },
   "outputs": [],
   "source": [
    "# SparkSession initialization\n",
    "conf = SparkConf().setAppName(\"Similar_Documents\")\n",
    "spark = SparkSession.builder.enableHiveSupport().config(conf = conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "type(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "46Rt4kzBWhet"
   },
   "outputs": [],
   "source": [
    "# Reading Dataset from Google Drive\n",
    "file_path = \"/content/gdrive/My Drive/Massive_Data_Project/Job_Dataset/job_summary.csv\"\n",
    "\n",
    "df_Dataset = spark.read.csv(file_path, header=True, inferSchema=True, multiLine=True, escape='\"',\n",
    "                           encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choosing chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zY17Y2KDWhet"
   },
   "outputs": [],
   "source": [
    "# Creating Chunk of Dataset\n",
    "import pandas as pd\n",
    "\n",
    "size = 5000\n",
    "df_Dataset_2 = df_Dataset.limit(size)\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "df_Dataset_2 = df_Dataset_2.toPandas()\n",
    "df_Dataset_2.to_csv('/content/gdrive/My Drive/Massive_Data_Project/Job_Dataset/Chunk5000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lyCtz89wNk0E"
   },
   "outputs": [],
   "source": [
    "# Reading Chunk Dataset\n",
    "file_path = \"/content/gdrive/My Drive/Massive_Data_Project/Job_Dataset/Chunk5000.csv\"\n",
    "\n",
    "Job_Dataset = spark.read.csv(file_path, header=True, inferSchema=True, multiLine=True, escape='\"',\n",
    "                           encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "b3Fc066TLhRe",
    "outputId": "47a94406-0b31-4149-e4ff-d891c0953303"
   },
   "outputs": [],
   "source": [
    "type(Job_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCYqdniVjwGY"
   },
   "source": [
    "# Pre-processsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieKXULV3j8IO"
   },
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaRQ2LhLj0ku",
    "outputId": "0a07af14-9211-4e46-f8d4-6d61e3f47a90"
   },
   "outputs": [],
   "source": [
    "Job_Dataset.show(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUkJ2ZU9j0h7",
    "outputId": "f2470460-50fe-45af-b37f-9fd2981f58c5"
   },
   "outputs": [],
   "source": [
    "Job_Dataset = Job_Dataset.select(\"job_summary\")\n",
    "Job_Dataset.show(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giving Id for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EeH8BXMtj0gE"
   },
   "outputs": [],
   "source": [
    "indexed_rdd = Job_Dataset.rdd.zipWithIndex()\n",
    "Job_Dataset = indexed_rdd.map(lambda x: (x[1], x[0][0])).toDF([\"Id\", \"job_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkVmLuZ7mh5V",
    "outputId": "110fc7e4-931d-455c-db7e-c0799d3aba3d"
   },
   "outputs": [],
   "source": [
    "Job_Dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rFMjdIf5mSN4"
   },
   "outputs": [],
   "source": [
    "Job_df = Job_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPU06lArj0dI",
    "outputId": "839877c6-3115-4c37-9416-c56791a06252"
   },
   "outputs": [],
   "source": [
    "Job_df.show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGL7HMGXj0Fc",
    "outputId": "b16299a0-643a-4831-f57e-c71b07b6e76a"
   },
   "outputs": [],
   "source": [
    "# checking missing values in the columns\n",
    "Job_df.select([count(when(isnan(c), c)).alias(c) for c in Job_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zUn4bFXj0DE",
    "outputId": "e9ff8933-cabf-470b-918e-5f188dab5fb3"
   },
   "outputs": [],
   "source": [
    "#count distinct values in each column\n",
    "Job_df.select([countDistinct(c).alias(c) for c in Job_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42-dyKZTllUH"
   },
   "source": [
    "### Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoQD6ewcjz_8",
    "outputId": "44e18647-d79f-4818-d8b7-f90c61f30a72"
   },
   "outputs": [],
   "source": [
    "# show duplicates in Body column\n",
    "Job_df.groupBy(\"job_summary\").count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVe3kM9GlpDe",
    "outputId": "5db32540-6570-466b-b516-10b73c070d96"
   },
   "outputs": [],
   "source": [
    "# Filter the rows where 'job_summary' starts with 'Job Title:\\nCerti'\n",
    "filtered_rows = Job_df.filter(col(\"job_summary\").startswith(\"Job Title:\\nCertified Nursing Assistant (CNA)\\nCompany\"))\n",
    "filtered_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "viD05Oxplows",
    "outputId": "075f37de-952f-4ed3-acbe-a55b13380b3e"
   },
   "outputs": [],
   "source": [
    "# ID number 1319\n",
    "row_with_id_1319 = Job_df.filter(Job_df['ID'] == 1319).collect()\n",
    "\n",
    "txt = row_with_id_1319[0][1:][0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "3J8yiQGgmOng",
    "outputId": "5fd88862-15b0-422e-f707-ad345ba04d77"
   },
   "outputs": [],
   "source": [
    "# ID number 1586\n",
    "row_with_id_1586 = Job_df.filter(Job_df['ID'] == 1586).collect()\n",
    "\n",
    "txt2 = row_with_id_1586[0][1:][0]\n",
    "txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nwRzE6SmSgT",
    "outputId": "a0adaa29-3fd3-40c4-8c3b-12bf600127d8"
   },
   "outputs": [],
   "source": [
    "# Checking Equality of texts\n",
    "if txt == txt2:\n",
    "    print('Equal')\n",
    "else:\n",
    "    print('Not Equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm1VjeEJmmhM"
   },
   "source": [
    "### Delete Duplicates Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Di1Qu4rlmk2D"
   },
   "outputs": [],
   "source": [
    "# Optionally, delete duplicates based on a specific column\n",
    "Job_df = Job_df.dropDuplicates(['job_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvYxt-5tm_s7",
    "outputId": "e7ea6eb2-693a-48a5-d6db-4d71468ee53c"
   },
   "outputs": [],
   "source": [
    "#count distinct values in each column\n",
    "Job_df.select([countDistinct(c).alias(c) for c in Job_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yyi-AEqGm_ql",
    "outputId": "f0cfe650-bbd8-4d6e-ac91-e51a3705184c"
   },
   "outputs": [],
   "source": [
    "# checking again duplicates\n",
    "Job_df.groupBy(\"job_summary\").count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyUy4TN8m_ny",
    "outputId": "c92d24cc-477a-4499-a3e5-bd7a2831534f"
   },
   "outputs": [],
   "source": [
    "row_with_id_1586 = Job_df.filter(Job_df['ID'] == 1586).collect()\n",
    "row_with_id_1586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VI6_yAS0npTK"
   },
   "source": [
    "# Text cleaning and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1PbihzgXm_lg"
   },
   "outputs": [],
   "source": [
    "Job_df = Job_df.select('Id',\"job_summary\")\n",
    "# questions_body.show(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaDAbp-bn5-r"
   },
   "source": [
    "### LoweCasing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tErqjlDdm_is"
   },
   "outputs": [],
   "source": [
    "Job_df = Job_df.withColumn('job_summary', lower(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZRXRdjQohHL"
   },
   "source": [
    "### Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "eJdudCgNm_f6"
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text) if text else text\n",
    "\n",
    "# Register the function as a UDF\n",
    "remove_html_tags_udf = udf(remove_html_tags, StringType())\n",
    "\n",
    "# Apply the UDF to the job_summary column\n",
    "Job_df = Job_df.withColumn('job_summary', remove_html_tags_udf(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "74cl8cUiwJJf"
   },
   "outputs": [],
   "source": [
    "# Job_df.show(n = 5 , truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3FOznpvpVuM"
   },
   "source": [
    "###  Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "2qYOtisopNRY"
   },
   "outputs": [],
   "source": [
    "# Here We also Use Regular Expressions to Remove URLs from Text or Whole Corpus.\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "remove_url_udf = udf(remove_url, StringType())\n",
    "Job_df = Job_df.withColumn('job_summary', remove_url_udf(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "E6xNY7DgwW_w"
   },
   "outputs": [],
   "source": [
    "# Job_df.show(n = 5 , truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz2uESZgph30"
   },
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "wUN3D1dMpNMI"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "remove_punctuation_udf = udf(remove_punctuation, StringType())\n",
    "Job_df = Job_df.withColumn('job_summary', remove_punctuation_udf(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Ml_FO2T1wah9"
   },
   "outputs": [],
   "source": [
    "# Job_df.show(n = 5 , truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjPqJsmxGjK2"
   },
   "source": [
    "### Remove numbers\n",
    "\n",
    "The following document has aroud 42 different number inside it, so we need to delet them.\n",
    "3x12 , 180000060000, 12003, 0, 4, 02142024, 05152024, 13, 556166975, 56166975 , 12 , 7 , 7, 100 , 133, 3467, 68100, 10 , 25, 50 , 100,\n",
    "100 , 20 , 3, 2, , 1, 0, 100, 15, 15, 15, 91, 401,36, 50, 2023, 2022, 2021 ,2020, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "XtLe-jovpNJl"
   },
   "outputs": [],
   "source": [
    "# row_with_id_160 = Job_df.filter(Job_df['ID'] == 160).collect()\n",
    "# row_with_id_160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Z0KRZ9xIw2r0"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "remove_numbers_udf = udf(remove_numbers, StringType())\n",
    "Job_df = Job_df.withColumn('job_summary', remove_numbers_udf(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "60FiTgIHpNAT"
   },
   "outputs": [],
   "source": [
    "# row_with_id_160 = Job_df.filter(Job_df['ID'] == 160).collect()\n",
    "# row_with_id_160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1opJKf--H4ao"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAIjcHRBJPRs"
   },
   "source": [
    "### Remove Non-ASCII characters:\n",
    "Some texts have some non-ASCII characters like (ã°â\\x9fâ\\x9fâ¡), so we need to delete them from texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "QzFylz4ZH4VR"
   },
   "outputs": [],
   "source": [
    "row_with_id_915 = Job_df.filter(Job_df['ID'] == 915).collect()\n",
    "row_with_id_915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "QoowVAkiGogf"
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', str(text))\n",
    "\n",
    "remove_non_ascii_udf = udf(remove_non_ascii, StringType())\n",
    "Job_df = Job_df.withColumn('job_summary', remove_non_ascii_udf(Job_df['job_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "YhO9wxvhH4Qv"
   },
   "outputs": [],
   "source": [
    "# checking again non-ASCII characters \n",
    "row_with_id_915 = Job_df.filter(Job_df['ID'] == 915).collect()\n",
    "row_with_id_915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suADkpQqKsDz"
   },
   "source": [
    "### Remove extra space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Jbbv0O2kKgkp"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, trim\n",
    "\n",
    "def remove_extra_spaces(df, column_name):\n",
    "    df = df.withColumn(column_name, regexp_replace(col(column_name), \"\\\\s+\", \" \"))  \n",
    "    return df.withColumn(column_name, trim(col(column_name))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "k8Dbz0BIKgiI"
   },
   "outputs": [],
   "source": [
    "Job_df = remove_extra_spaces(Job_df, \"job_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFjhZHglpnYM",
    "outputId": "d16dcf88-5204-400c-ac67-b0f57f368320"
   },
   "outputs": [],
   "source": [
    "Job_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ETJ4cz1LCOg"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9trSn1OKggA",
    "outputId": "5a0255cc-21b7-4478-f894-8dee5411990b"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCol(\"job_summary\").setOutputCol(\"Tokens\")\n",
    "Job_df = tokenizer.transform(Job_df)\n",
    "Job_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvws70vULf5W"
   },
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odmYIctMKgdf",
    "outputId": "44197ccb-c453-4468-da39-c971a6866127"
   },
   "outputs": [],
   "source": [
    "# removing stopwords using default list\n",
    "remove_stopwords = StopWordsRemover()\n",
    "stopwords = remove_stopwords.getStopWords()\n",
    "print(stopwords[:10])\n",
    "print(len(stopwords))\n",
    "\n",
    "remove_stopwords.setInputCol(\"Tokens\").setOutputCol(\"Tokens stopwords removed\")\n",
    "Job_df = remove_stopwords.transform(Job_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OhDrnVUfLuB1"
   },
   "outputs": [],
   "source": [
    "# # counting the number of tokens with stopwords removed\n",
    "Job_df = Job_df.withColumn(\"Number of tokens\", size(Job_df['Tokens']))\n",
    "Job_df = Job_df.withColumn(\"Number of tokens After stopwords removed\", size(Job_df['Tokens stopwords removed']))\n",
    "# counting the number of tokens with stopwords removed\n",
    "Job_df = Job_df.withColumn(\"Number of stopwords removed\", size(Job_df['Tokens stopwords removed']) - size(Job_df['Tokens']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzlMusQnrPQB",
    "outputId": "22d3872f-4923-4bc3-a9d0-4f6bbc721cd9"
   },
   "outputs": [],
   "source": [
    "Job_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbgLohL-91x2"
   },
   "source": [
    "###  Join the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYGnoUbE9xAT"
   },
   "source": [
    "To join the words back together after tokenization and stopword removal, you can use the concat_ws function provided by PySpark. Here’s how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "kSrn4KhK9nHM"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "Job_df = Job_df.withColumn(\"Cleaned_text\", concat_ws(\" \", col(\"Tokens stopwords removed\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7xpWGmYr28z",
    "outputId": "869e78c4-d1c8-46a4-bb34-799c74c36347"
   },
   "outputs": [],
   "source": [
    "Job_df.select(\"Cleaned_text\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXPxWKx9L5a5"
   },
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "MLsQ5XcBLu8K"
   },
   "outputs": [],
   "source": [
    "Job_df_proces = Job_df.select('Id', \"Cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7xSwSLduTZC",
    "outputId": "83883e7b-3132-44ed-a52c-d6cf1b2de645"
   },
   "outputs": [],
   "source": [
    "Job_df_proces.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qjKhcqCtQP6u"
   },
   "outputs": [],
   "source": [
    "def shingle(text, k):\n",
    "    shingles = set()\n",
    "    words = text.split()\n",
    "    for i in range(len(words) - k + 1):\n",
    "        shingles.add(' '.join(words[i:i+k]))\n",
    "    return list(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nVIt5xhg-s_Z"
   },
   "outputs": [],
   "source": [
    "k = 2  # Shingle length\n",
    "shingle_udf = udf(lambda text: shingle(text, k), ArrayType(StringType()))\n",
    "Job_df_proces = Job_df_proces.withColumn(\"shingles\", shingle_udf(col(\"Cleaned_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-GefdX8kFhK",
    "outputId": "01b4ca2e-9a50-4afe-ea03-b0bdb9df165b"
   },
   "outputs": [],
   "source": [
    "Job_df_proces.select(\"shingles\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert shingles to sparse vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98WSxCC7YYYy",
    "outputId": "05407cc8-a424-4521-d770-a319b21d85ec"
   },
   "outputs": [],
   "source": [
    "# Flatten the shingles column to get all unique shingles\n",
    "unique_shingles = Job_df_proces.select(explode(\"shingles\").alias(\"shingle\")).distinct().collect()\n",
    "shingle_index = {row[\"shingle\"]: idx for idx, row in enumerate(unique_shingles)}\n",
    "\n",
    "print(\"Unique shingles and their indices:\")\n",
    "print(shingle_index)\n",
    "\n",
    "def shingles_to_sparse_vector(shingles):\n",
    "    indices = sorted([shingle_index[sh] for sh in shingles if sh in shingle_index])\n",
    "    values = [1.0] * len(indices)\n",
    "    return Vectors.sparse(len(unique_shingles), indices, values)\n",
    "\n",
    "# UDF to convert shingles to sparse vectors\n",
    "sparse_vector_udf = udf(lambda shingles: shingles_to_sparse_vector(shingles), VectorUDT())\n",
    "\n",
    "Job_df_proces = Job_df_proces.withColumn(\"features\", sparse_vector_udf(col(\"shingles\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aTBcxCRtx2l",
    "outputId": "d24f692f-8419-44de-d5d6-b70d2a3c0d93"
   },
   "outputs": [],
   "source": [
    "# Show the DataFrame with sparse vectors\n",
    "Job_df_proces.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "XoorQhepv23o"
   },
   "outputs": [],
   "source": [
    "df = Job_df_proces\n",
    "# df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ks6uAGuN5hcb",
    "outputId": "ad102341-f40c-416d-908d-10cec203f45b"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Initialize MinHashLSH\n",
    "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", seed=12345, numHashTables=20)\n",
    "model = mh.fit(df)\n",
    "print(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n",
    "hash = model.transform(df)\n",
    "\n",
    "# Compute the locality sensitive hashes for the input rows, then perform approximate\n",
    "# similarity join to Calculate Jaccard Distances.\n",
    "result = model.approxSimilarityJoin(hash, hash, 0.6, distCol=\"JaccardDistance\").select(\n",
    "    col(\"datasetA.id\").alias(\"idA\"),\n",
    "    col(\"datasetB.id\").alias(\"idB\"),\n",
    "    col(\"JaccardDistance\")\n",
    ")\n",
    "\n",
    "# Filter out self-pairs and display the results\n",
    "result_filtered = result.filter(\"idA < idB\")\n",
    "\n",
    "end = time.time()\n",
    "computation_time = round(end - start, 3)\n",
    "print(\"Computation time: {} seconds\".format(computation_time))\n",
    "\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "_JLdmJFmc5Zm",
    "outputId": "5b811118-9cbf-413b-caff-8f0f146a0c01"
   },
   "outputs": [],
   "source": [
    "type(result_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_a36H2GOvUN4",
    "outputId": "72f5c6a5-24de-4513-c72c-7037a12a036f"
   },
   "outputs": [],
   "source": [
    "result_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYWHOzqMv16I",
    "outputId": "603cb65f-c624-4e02-aa9a-91530ccd9524"
   },
   "outputs": [],
   "source": [
    "# showing id pairs with distance < 0.6 sorted in ascending order\n",
    "result_filtered.sort(result_filtered.JaccardDistance.asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsuKatxZv12T",
    "outputId": "75259467-d843-4d7d-91ea-98d13bc792ac"
   },
   "outputs": [],
   "source": [
    "result_filtered.sort(result_filtered.JaccardDistance.desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv88KaZHyhdS"
   },
   "source": [
    "#### save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0kija3Kxn1Z",
    "outputId": "c83cf49c-eb31-4ceb-d334-7933a5872f0f"
   },
   "outputs": [],
   "source": [
    "# save the result to a file\n",
    "start = time.time()\n",
    "\n",
    "size = 5000\n",
    "result_path = f\"/content/gdrive/My Drive/Massive_Data_Project/Result/results_{size}.csv\"\n",
    "result_filtered.write.csv(result_path, header=True)\n",
    "print('------------- Result Saved ---------------')\n",
    "\n",
    "end = time.time()\n",
    "computation_time = round(end - start, 3)\n",
    "print(\"Computation time: {} seconds\".format(computation_time))\n",
    "print('------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hhphKJFR5A8"
   },
   "source": [
    "#### Load the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "WP9mNUXDLu0p"
   },
   "outputs": [],
   "source": [
    "# Load the result back from the saved CSV file\n",
    "size = 5000\n",
    "loaded_result_path = f\"/content/gdrive/My Drive/Massive_Data_Project/Result/results_{size}.csv\"\n",
    "loaded_result = spark.read.csv(loaded_result_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTjTF1evLuxw",
    "outputId": "7aef00b8-e810-4aeb-be49-b12f7463a86a"
   },
   "outputs": [],
   "source": [
    "loaded_result.sort(loaded_result.JaccardDistance.asc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD1dC-SVVYIx",
    "outputId": "da6bb338-0c10-4e5a-830e-7129d412da4d"
   },
   "outputs": [],
   "source": [
    "# Filter the results to show only rows with JaccardDistance between 0.2 and 0.3\n",
    "filtered_result = loaded_result.filter((loaded_result.JaccardDistance >= 0.2) & (loaded_result.JaccardDistance <= 0.3))\n",
    "filtered_result.sort(filtered_result.JaccardDistance.asc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qstGEpIdSZbc"
   },
   "source": [
    "#### Result of minhash function (hash values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fD4bpJ27Lus-",
    "outputId": "cad95d43-a621-41a3-a3b7-8718f9417b3a"
   },
   "outputs": [],
   "source": [
    "hash.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YFR2Dy9WhfA"
   },
   "source": [
    "#### Sparce vector for first document , id = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEYHI8RjROKN",
    "outputId": "aa602c6d-1e0c-4601-c8e4-e0d6784ef8f8"
   },
   "outputs": [],
   "source": [
    "hash.first()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CMLWrehTMpN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWOyzTwkWhfA"
   },
   "source": [
    "#### Signature vector for first document, id = 160\n",
    "Values inside DenseVector shows value of each hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9Z45IyVROG4",
    "outputId": "60c0e580-8014-46eb-8273-e1ad6048eed4"
   },
   "outputs": [],
   "source": [
    "# hash value of first Document\n",
    "hash.first()['hashes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrTcMm4Yz865"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71mSHKCVzfu6"
   },
   "source": [
    "### Creating New dataframe in order to compare pair document with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0POYM2OLzXvY",
    "outputId": "285dafd9-e91f-4ce6-b837-0390dd1bca82"
   },
   "outputs": [],
   "source": [
    "df_compare = Job_df.select('Id', \"Tokens stopwords removed\")\n",
    "df_compare.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "h5TnIF1WhZ44"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Filter the dataset to get the row with the given ID number\n",
    "def analyze_text_by_id(df: DataFrame, id_number: int):\n",
    "    row_with_id = df.filter(df['ID'] == id_number).collect()\n",
    "    print(row_with_id)\n",
    "\n",
    "    if not row_with_id:\n",
    "        print(f\"No row found with ID {id_number}\")\n",
    "        return\n",
    "\n",
    "    txt = row_with_id[0][1:][0]\n",
    "\n",
    "    print(f\"Type of txt: {type(txt)}\")\n",
    "    print(f\"Length of txt: {len(txt)}\")\n",
    "    print(f\"Fourth character in txt: {txt[3]}\")\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "rya7IKnL6GLR"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the number of words, common words, and percentage of common words\n",
    "def analyze_lists(tokens1, tokens2):\n",
    "    tokens1 = [word for word in tokens1 if word]\n",
    "    tokens2 = [word for word in tokens2 if word]\n",
    "\n",
    "    num_words_list1 = len(tokens1)\n",
    "    num_words_list2 = len(tokens2)\n",
    "    num_unique_words_list1 = len(set(tokens1))\n",
    "    num_unique_words_list2 = len(set(tokens2))\n",
    "\n",
    "    common_words = set(tokens1).intersection(tokens2)\n",
    "    num_common_words = len(common_words)\n",
    "\n",
    "    percentage_common_list1 = (num_common_words / num_unique_words_list1) * 100 if num_unique_words_list1 > 0 else 0\n",
    "    percentage_common_list2 = (num_common_words / num_unique_words_list2) * 100 if num_unique_words_list2 > 0 else 0\n",
    "\n",
    "    return (num_words_list1, num_words_list2, num_unique_words_list1,\n",
    "            num_unique_words_list2, num_common_words,\n",
    "            percentage_common_list1, percentage_common_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpfXgancVA0h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_lwJOnlzKxD"
   },
   "source": [
    "### Comparing the Documents with 'ID' number of 1909 & 3014, which have Jaccard distance equal to 0.20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u49-zW9RN8b",
    "outputId": "9aa2ac8c-1cae-4ddc-ae1d-affd6a744324"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 1909\n",
    "txt1 = analyze_text_by_id(df_compare, 1909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPCo62tESFsv",
    "outputId": "6debc7ae-ab59-4c49-ccba-f7be1b064a30"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 3014\n",
    "txt2 = analyze_text_by_id(df_compare, 3014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AymhKdfOSJz7",
    "outputId": "fb6c12ea-9c92-4b0e-9b72-4a94787088a6"
   },
   "outputs": [],
   "source": [
    "# Comparing number of common words inside Documents with 'ID' number of 1909 & 3014\n",
    "\n",
    "(num_words_list1, num_words_list2, num_unique_words_list1,\n",
    " num_unique_words_list2, num_common_words,\n",
    " percentage_common_list1, percentage_common_list2) = analyze_lists(txt1, txt2)\n",
    "\n",
    "print(f\"Number of words in Text_1: {num_words_list1}\")\n",
    "print(f\"Number of words in Text_2: {num_words_list2}\")\n",
    "print(f\"Number of Unique words in Text_1: {num_unique_words_list1}\")\n",
    "print(f\"Number of Unique words in Text_2: {num_unique_words_list2}\")\n",
    "print(f\"Number of common Uniqe words: {num_common_words}\")\n",
    "print(f\"Percentage of common words in Text_1: {percentage_common_list1:.2f}%\")\n",
    "print(f\"Percentage of common words in Text_2: {percentage_common_list2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07IsXkar8NtM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWCJl4vX8azC"
   },
   "source": [
    "### Comparing the Documents with 'ID' number of 3284 & 4955, which have Jaccard distance equal to 0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OF9mSBuq8NZz",
    "outputId": "7eceace3-8c6f-4ffd-df79-daae860dec76"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 3284\n",
    "txt5 = analyze_text_by_id(df_compare, 3284)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfLHNPgd8NW6",
    "outputId": "5bbcb278-3760-48c4-b5ea-82f426b65cf8"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 4955\n",
    "txt6 = analyze_text_by_id(df_compare, 4955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THI9u5OA8zKZ",
    "outputId": "a131804a-7829-435b-a7fd-a003d08220bc"
   },
   "outputs": [],
   "source": [
    "# Comparing number of common words inside Documents with 'ID' number of 3284 & 4955\n",
    "\n",
    "(num_words_list1, num_words_list2, num_unique_words_list1,\n",
    " num_unique_words_list2, num_common_words,\n",
    " percentage_common_list1, percentage_common_list2) = analyze_lists(txt5, txt6)\n",
    "\n",
    "print(f\"Number of words in Text_1: {num_words_list1}\")\n",
    "print(f\"Number of words in Text_2: {num_words_list2}\")\n",
    "print(f\"Number of Unique words in Text_1: {num_unique_words_list1}\")\n",
    "print(f\"Number of Unique words in Text_2: {num_unique_words_list2}\")\n",
    "print(f\"Number of common Uniqe words: {num_common_words}\")\n",
    "print(f\"Percentage of common words in Text_1: {percentage_common_list1:.2f}%\")\n",
    "print(f\"Percentage of common words in Text_2: {percentage_common_list2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFy2-wHaXnsh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzWOQBVSXzcu"
   },
   "source": [
    "### Comparing the Documents with 'ID' number of 503 & 948, which have Jaccard distance equal to 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuYF5xeJXnpn",
    "outputId": "5f5d0415-9667-45d5-f2d4-cb267072b34d"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 503\n",
    "txt3 = analyze_text_by_id(df_compare, 503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8PuUgYzXnmK",
    "outputId": "bf2bea26-d872-4174-d237-bc31f08ecd0c"
   },
   "outputs": [],
   "source": [
    "# Filter the dataset to get the row with ID number 948\n",
    "txt4 = analyze_text_by_id(df_compare, 948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMilCjeNX6Ax",
    "outputId": "3ac7cbad-3eb4-4b03-b676-aa07bdbf6ba7"
   },
   "outputs": [],
   "source": [
    "# Comparing number of common words inside Documents with 'ID' number of 503 & 948\n",
    "\n",
    "(num_words_list1, num_words_list2, num_unique_words_list1,\n",
    " num_unique_words_list2, num_common_words,\n",
    " percentage_common_list1, percentage_common_list2) = analyze_lists(txt3, txt4)\n",
    "\n",
    "print(f\"Number of words in Text_1: {num_words_list1}\")\n",
    "print(f\"Number of words in Text_2: {num_words_list2}\")\n",
    "print(f\"Number of Unique words in Text_1: {num_unique_words_list1}\")\n",
    "print(f\"Number of Unique words in Text_2: {num_unique_words_list2}\")\n",
    "print(f\"Number of common Uniqe words: {num_common_words}\")\n",
    "print(f\"Percentage of common words in Text_1: {percentage_common_list1:.2f}%\")\n",
    "print(f\"Percentage of common words in Text_2: {percentage_common_list2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCUJpwLndWX7"
   },
   "source": [
    "## Cheking the Equality of documents:\n",
    "#### Cheking the Equality of documents with ['ID'] number 503 & 948, which they have Jaccard Distance equal to Zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "NQGDOn0bbt-y",
    "outputId": "66fd9870-362d-4cd4-9ef8-19f43c84308e"
   },
   "outputs": [],
   "source": [
    "# ID number 503\n",
    "row_with_id_503 = Job_Dataset.filter(Job_Dataset['ID'] == 503).collect()\n",
    "txt = row_with_id_503[0][1:][0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "1QwJ2wR4bt1m",
    "outputId": "6409ae66-06af-4020-bfee-0970a0a74ebb"
   },
   "outputs": [],
   "source": [
    "# ID number 948\n",
    "row_with_id_948 = Job_Dataset.filter(Job_Dataset['ID'] == 948).collect()\n",
    "txt2 = row_with_id_948[0][1:][0]\n",
    "txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCGTynSJbty7",
    "outputId": "e38ebdef-45b4-4883-afe2-6e0e56540623"
   },
   "outputs": [],
   "source": [
    "if txt == txt2:\n",
    "    print('Equal')\n",
    "else:\n",
    "    print('Not Equal')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
